{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/code/semeval/experiments/kosenko/language_bind/LanguageBind/languagebind/audio/processing_audio.py:17: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "\n",
    "\n",
    "from semeval.experiments.kosenko.language_bind.LanguageBind.languagebind import (\n",
    "    LanguageBind,\n",
    "    to_device,\n",
    "    transform_dict,\n",
    "    LanguageBindImageTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "device = torch.device(device)\n",
    "clip_type = {\n",
    "    \"video\": \"LanguageBind_Video_FT\",  # also LanguageBind_Video\n",
    "    # \"audio\": \"LanguageBind_Audio_FT\",  # also LanguageBind_Audio\n",
    "    # \"thermal\": \"LanguageBind_Thermal\",\n",
    "    # \"image\": \"LanguageBind_Image\",\n",
    "    # \"depth\": \"LanguageBind_Depth\",\n",
    "}\n",
    "\n",
    "languagebind_model = LanguageBind(clip_type=clip_type, cache_dir=\"/code/cache_dir\")\n",
    "languagebind_model = languagebind_model.to(device)\n",
    "# model.eval()\n",
    "pretrained_ckpt = f\"LanguageBind/LanguageBind_Image\"\n",
    "tokenizer = LanguageBindImageTokenizer.from_pretrained(\n",
    "    pretrained_ckpt, cache_dir=\"/code/cache_dir/tokenizer_cache_dir\"\n",
    ")\n",
    "modality_transform = {\n",
    "    c: transform_dict[c](languagebind_model.modality_config[c])\n",
    "    for c in clip_type.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7536, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "video = [\n",
    "    \"semeval/experiments/kosenko/language_bind/LanguageBind/assets/video/0.mp4\",\n",
    "    \"semeval/experiments/kosenko/language_bind/LanguageBind/assets/video/0.mp4\",\n",
    "]\n",
    "language = [\n",
    "    \"Two pandas are eating bamboo.\",\n",
    "    \"Two pandas are eating bamboo.\",\n",
    "]\n",
    "\n",
    "inputs = {\n",
    "    \"video\": to_device(modality_transform[\"video\"](video), device),\n",
    "}\n",
    "inputs[\"language\"] = to_device(\n",
    "    tokenizer(\n",
    "        language,\n",
    "        max_length=77,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ),\n",
    "    device,\n",
    ")\n",
    "\n",
    "\n",
    "class VideoTextClassif(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = languagebind_model\n",
    "        self.linear = torch.nn.Linear(768 * 2, 2, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.model(x)\n",
    "        # print(result)\n",
    "        features = torch.cat(\n",
    "            [\n",
    "                result[\"video\"],\n",
    "                result[\"language\"],\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        result = self.linear(features)\n",
    "        return result\n",
    "\n",
    "\n",
    "text_video_classif = VideoTextClassif()\n",
    "text_video_classif.to(device)\n",
    "output = text_video_classif(inputs)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_func(output, torch.tensor([1, 0], device=device))\n",
    "print(loss)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент 1\n",
    "\n",
    "Классификатор на основе текста и видео. На вход подается независимая реплика диалога и соответствующее видео к нему. Никакой следующий контекст диалога не используется.\n",
    "\n",
    "На основе этого нужно предсказать эмоцию, то есть класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374\n",
      "13619\n",
      "{'surprise': 0, 'fear': 1, 'sadness': 2, 'neutral': 3, 'joy': 4, 'anger': 5, 'disgust': 6}\n",
      "{0: 'surprise', 1: 'fear', 2: 'sadness', 3: 'neutral', 4: 'joy', 5: 'anger', 6: 'disgust'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'utterance_ID': tensor([ 1, 10]),\n",
       " 'text': ['Th ... th ... that is all it is , a third nipple .', 'What ? !'],\n",
       " 'speaker': ['Ross', 'Phoebe'],\n",
       " 'emotion': ['neutral', 'surprise'],\n",
       " 'video_name': ['/code/SemEval-2024_Task3/training_data/train/dia424utt1.mp4',\n",
       "  '/code/SemEval-2024_Task3/training_data/train/dia1255utt10.mp4'],\n",
       " 'label': tensor([3, 0])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def random_seed(seed=42, rank=0):\n",
    "    torch.manual_seed(seed + rank)\n",
    "    np.random.seed(seed + rank)\n",
    "    random.seed(seed + rank)\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from torchvision.io import read_video\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "dataset_path = \"./SemEval-2024_Task3/training_data/Subtask_2_train.json\"\n",
    "\n",
    "\n",
    "dataset = json.loads(open(dataset_path).read())\n",
    "print(len(dataset))\n",
    "\n",
    "\n",
    "# dataset[0]\n",
    "\n",
    "\n",
    "all_conversations = []\n",
    "\n",
    "\n",
    "for item in dataset:\n",
    "    all_conversations.extend(item[\"conversation\"])\n",
    "print(len(all_conversations))\n",
    "\n",
    "\n",
    "# all_emotions = set([])\n",
    "\n",
    "\n",
    "# for item in all_conversations:\n",
    "\n",
    "\n",
    "#     all_emotions.update([item[\"emotion\"]])\n",
    "# for item in all_conversations:\n",
    "#     print(item['video_name'])\n",
    "\n",
    "\n",
    "# print(all_emotions)\n",
    "\n",
    "\n",
    "all_emotions = [\n",
    "    \"surprise\",\n",
    "    \"fear\",\n",
    "    \"sadness\",\n",
    "    \"neutral\",\n",
    "    \"joy\",\n",
    "    \"anger\",\n",
    "    \"disgust\",\n",
    "]\n",
    "\n",
    "\n",
    "emotions2labels = {em: i for i, em in enumerate(all_emotions)}\n",
    "labels2emotions = {i: em for i, em in enumerate(all_emotions)}\n",
    "\n",
    "\n",
    "print(emotions2labels)\n",
    "print(labels2emotions)\n",
    "\n",
    "\n",
    "all_data = datasets.Dataset.from_list(all_conversations)\n",
    "all_data = all_data.train_test_split(\n",
    "    test_size=0.08,\n",
    "    seed=42,\n",
    ")\n",
    "training_data, test_data = all_data[\"train\"], all_data[\"test\"]\n",
    "\n",
    "\n",
    "class ConversationsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        conversations,\n",
    "        base_video_path=None,\n",
    "    ):\n",
    "        self.conversations = conversations\n",
    "\n",
    "        self.base_video_path = base_video_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conversations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        turn = self.conversations[idx]\n",
    "\n",
    "        video_path = turn[\"video_name\"]\n",
    "\n",
    "        turn[\"video_name\"] = f\"{self.base_video_path}/{video_path}\"\n",
    "\n",
    "        turn[\"label\"] = emotions2labels[turn[\"emotion\"]]\n",
    "\n",
    "        return turn\n",
    "\n",
    "\n",
    "training_data = ConversationsDataset(\n",
    "    conversations=training_data,\n",
    "    base_video_path=\"/code/SemEval-2024_Task3/training_data/train\",\n",
    ")\n",
    "test_data = ConversationsDataset(\n",
    "    conversations=test_data,\n",
    "    base_video_path=\"/code/SemEval-2024_Task3/training_data/train\",\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=2, shuffle=False)\n",
    "\n",
    "\n",
    "next(iter(test_dataloader))\n",
    "# all_data.push_to_hub(\n",
    "#     \"dim/SemEval_training_data_emotions\",\n",
    "#     token=open(\"./hf_token\").read(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13619, 13074, 545)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_conversations), len(training_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utterance_ID', 'text', 'speaker', 'emotion', 'video_name', 'label']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(next(iter(train_dataloader)).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/code/semeval/experiments/kosenko/language_bind/LanguageBind/languagebind/audio/processing_audio.py:17: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "from semeval.experiments.kosenko.language_bind.LanguageBind.languagebind import (\n",
    "    LanguageBind,\n",
    "    to_device,\n",
    "    transform_dict,\n",
    "    LanguageBindImageTokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "class VideoTextClassif(torch.nn.Module):\n",
    "    def __init__(self, labels=2, clip_type=None):\n",
    "        super().__init__()\n",
    "        self.model = LanguageBind(\n",
    "            clip_type=clip_type,\n",
    "            cache_dir=\"/code/cache_dir\",\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(\n",
    "            768 * 2,\n",
    "            labels,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.model(x)\n",
    "        # print(result)\n",
    "        features = torch.cat(\n",
    "            [\n",
    "                result[\"video\"],\n",
    "                result[\"language\"],\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        result = self.linear(features)\n",
    "        return result\n",
    "\n",
    "\n",
    "device = \"cuda:0\"\n",
    "device = torch.device(device)\n",
    "clip_type = {\n",
    "    \"video\": \"LanguageBind_Video_FT\",\n",
    "}\n",
    "text_video_classif = VideoTextClassif(\n",
    "    labels=len(all_emotions),\n",
    "    clip_type=clip_type,\n",
    ")\n",
    "text_video_classif = text_video_classif.to(device)\n",
    "pretrained_ckpt = f\"LanguageBind/LanguageBind_Image\"\n",
    "tokenizer = LanguageBindImageTokenizer.from_pretrained(\n",
    "    pretrained_ckpt, cache_dir=\"/code/cache_dir/tokenizer_cache_dir\"\n",
    ")\n",
    "modality_transform = {\n",
    "    c: transform_dict[c](text_video_classif.model.modality_config[c])\n",
    "    for c in clip_type.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "text_video_classif.eval()\n",
    "batch = next(iter(train_dataloader))\n",
    "inputs = {\n",
    "    \"video\": to_device(\n",
    "        modality_transform[\"video\"](batch[\"video_name\"]),\n",
    "        device,\n",
    "    ),\n",
    "    \"language\": to_device(\n",
    "        tokenizer(\n",
    "            batch[\"text\"],\n",
    "            max_length=77,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ),\n",
    "        device,\n",
    "    ),\n",
    "}\n",
    "\n",
    "result = text_video_classif(inputs)\n",
    "predicted_labels = result.argmax(-1).cpu().numpy()\n",
    "test_f1_score = f1_score(\n",
    "    batch[\"label\"].numpy(),\n",
    "    predicted_labels,\n",
    "    average=\"macro\",\n",
    ")\n",
    "print(test_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6992, device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    text_video_classif.parameters(),\n",
    "    lr=0.00001,\n",
    ")\n",
    "loss = loss_func(\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [0.45, 0.23],\n",
    "            [0.55, 0.33],\n",
    "        ],\n",
    "        device=device,\n",
    "    ),\n",
    "    torch.tensor([1, 0], device=device),\n",
    ")\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### super simple train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "max_train_steps = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for num_step, batch in tqdm.tqdm(enumerate(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        # print(batch)\n",
    "        inputs = {\n",
    "            \"video\": to_device(\n",
    "                modality_transform[\"video\"](batch[\"video_name\"]), device\n",
    "            ),\n",
    "            \"language\": to_device(\n",
    "                tokenizer(\n",
    "                    batch[\"text\"],\n",
    "                    max_length=77,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                ),\n",
    "                device,\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        result = text_video_classif(inputs)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        loss = loss_func(result, label)\n",
    "        print(num_step, loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if num_step > max_train_steps:\n",
    "            break\n",
    "\n",
    "    # for\n",
    "    #     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text_video_classif inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/code/semeval/experiments/kosenko/language_bind/LanguageBind/languagebind/audio/processing_audio.py:17: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "from semeval.experiments.kosenko.language_bind.languagebind_classification import (\n",
    "    VideoTextClassif,\n",
    ")\n",
    "from semeval.experiments.kosenko.language_bind.LanguageBind.languagebind import (\n",
    "    LanguageBind,\n",
    "    to_device,\n",
    "    transform_dict,\n",
    "    LanguageBindImageTokenizer,\n",
    ")\n",
    "import torch\n",
    "\n",
    "all_emotions = [\n",
    "    \"surprise\",\n",
    "    \"fear\",\n",
    "    \"sadness\",\n",
    "    \"neutral\",\n",
    "    \"joy\",\n",
    "    \"anger\",\n",
    "    \"disgust\",\n",
    "]\n",
    "\n",
    "\n",
    "emotions2labels = {em: i for i, em in enumerate(all_emotions)}\n",
    "\n",
    "\n",
    "labels2emotions = {i: em for i, em in enumerate(all_emotions)}\n",
    "device = \"cuda:0\"\n",
    "device = torch.device(device)\n",
    "clip_type = {\n",
    "    \"video\": \"LanguageBind_Video_FT\",\n",
    "}\n",
    "\n",
    "text_video_classif_default = VideoTextClassif(\n",
    "    labels=len(all_emotions),\n",
    "    clip_type=clip_type,\n",
    ")\n",
    "text_video_classif = VideoTextClassif(\n",
    "    labels=len(all_emotions),\n",
    "    clip_type=clip_type,\n",
    ")\n",
    "text_video_classif.to(device=device)\n",
    "text_video_classif_default.to(device=device)\n",
    "text_video_classif.load_state_dict(\n",
    "    torch.load(\n",
    "        \"./semeval/experiments/kosenko/language_bind/train_results/checkpoint-2040/pytorch_model.bin\"\n",
    "    )\n",
    ")\n",
    "text_video_classif.eval()\n",
    "text_video_classif_default.eval()\n",
    "\n",
    "\n",
    "pretrained_ckpt = f\"LanguageBind/LanguageBind_Image\"\n",
    "tokenizer = LanguageBindImageTokenizer.from_pretrained(\n",
    "    pretrained_ckpt, cache_dir=\"/code/cache_dir/tokenizer_cache_dir\"\n",
    ")\n",
    "modality_transform = {\n",
    "    c: transform_dict[c](text_video_classif.model.modality_config[c])\n",
    "    for c in clip_type.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374\n",
      "13619\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def random_seed(seed=42, rank=0):\n",
    "    torch.manual_seed(seed + rank)\n",
    "    np.random.seed(seed + rank)\n",
    "    random.seed(seed + rank)\n",
    "\n",
    "\n",
    "random_seed()\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset_path = \"./SemEval-2024_Task3/training_data/Subtask_2_train.json\"\n",
    "\n",
    "\n",
    "dataset = json.loads(open(dataset_path).read())\n",
    "print(len(dataset))\n",
    "\n",
    "all_conversations = []\n",
    "\n",
    "for item in dataset:\n",
    "    all_conversations.extend(item[\"conversation\"])\n",
    "print(len(all_conversations))\n",
    "\n",
    "\n",
    "training_data, test_data = train_test_split(\n",
    "    all_conversations,\n",
    "    test_size=0.04,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Whoa ho .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: No , I do not .\n",
      "Predicted: disgust\n",
      "Original: disgust\n",
      "===\n",
      "Text: We are you just ten seconds later !\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: And Ross gave me this great book\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: The movie theatre , you used to come in all the time .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Nope , nope , I would just ah , I would rather talk to you .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: No ... no , it is not okay !\n",
      "Predicted: neutral\n",
      "Original: sadness\n",
      "===\n",
      "Text: Okay sweetie , you can do it . Just open up and put it in your mouth .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: What happened to the Disgustingtons ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Hey !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: But we ... we did not have ... sex ... uh , did we ?\n",
      "Predicted: fear\n",
      "Original: fear\n",
      "===\n",
      "Text: What do you think you are gonna do , have sex with her right here on my couch ?\n",
      "Predicted: surprise\n",
      "Original: disgust\n",
      "===\n",
      "Text: No , no , that ... that , that is all right . Umm , I am just glad you called .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Okay , absolutely !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Oh ! Wow ! Uh , yeah ! That sounds great . I am just gonna put this back in my pocket , pretend that didn’t happen .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Thank God .\n",
      "Predicted: neutral\n",
      "Original: joy\n",
      "===\n",
      "Text: Hi !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Well , no . That is impossible . He can never be too Alan .\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: He is a he ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Yeah ! Now , why do you want to kill yourself ?\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: I talk to you and it is nothin .\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: Thank you !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Oh ? Really ? That is what my daughter means to you ? Nothing ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Oh , I am not doing it alone . I have Ross .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: God . Do you think it really does not hurt ? How can they do that ?\n",
      "Predicted: fear\n",
      "Original: fear\n",
      "===\n",
      "Text: Ross , you are like my best friend .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: You know it is ironic ...\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Thank you , Monica .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Yes , hi .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Julie cervix is dilated a seven centimeters , that is about four fingers . The doctor let me feel it myself .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: It is a long story but the things you just said really made my day !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Well honey , what about you ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Yeah , you should , really .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Bye ... bye ! That is why I moved out .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Okay , umm , why do not , why do not you all start to read , while I ...\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: I had such an opportunity in the recent , present .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Hi .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: And then you said , \" Why do they call it a check ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: You know , one of them had never been to a bachelor party before .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Eligible looters ?\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: Thanks , Chandler .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Yeah . Yeah ? Yeah .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: If you tell me , I will tell you what Phoebe said .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Now honey , you take care , you do not have those babies until I get back .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: One ticket to Yemen ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Man , I wish I was naked .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Well , I think this is a great place to work !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: You know I am ... I am really glad we decided not to sleep together before the wedding .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Hey !\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Oh well that is what I thought about my first husband , now I am lucky if my kid gets to spend the weekend with her father and the twins and little Ms . New Boobs .\n",
      "Predicted: sadness\n",
      "Original: disgust\n",
      "===\n",
      "Text: Every year .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: And then Ross new girlfriend , Bonnie , shows up and Rachel convinced her to save her head .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Perhaps . Now I am curious , at what point during those girlish screams would you have begun to kick my ass ?\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: Oh , I wanna quit , but then I think I should stick it out , then I think why would such a person stay in such a demeaning job , just because it is remotely related to the field they are interested in .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: Oh , I have not had that feeling since I first started going out with Chandler .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Ohh , I know one thing !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: We are still on this side of the door .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Chloe , switch with me , there is some guys here that got a crush on you .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: All right , just , just take the entertainment center , and then when you get home , throw the canoe away !\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Okay , you have 19 questions left . Use them wisely . Come on Joey ! You can not win if you do not ask any\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Hey . Soaps ? Shampoos ? Are you really taking all this stuff ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: If it was , would you stop hanging out with her ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Oh , great ! Me too .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Well , maybe it is a contest , you know ? Like , collect all five ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: How do you think she is doing ?\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: What are you talking about ? !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Yeah !\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: That is so silly .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: Well\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Thanks , bye .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Here you go , maybe this will cheer you up .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Five letters .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Oh .\n",
      "Predicted: anger\n",
      "Original: sadness\n",
      "===\n",
      "Text: Hey !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Well uh if you must know I am a widower .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: What are you talking about ? Lots of things rhyme with Rachel . Bagel . Mail . Jail . Bail . Able . May ... pole .\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Ok !\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Hi !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: The doctor is a monkey .\n",
      "Predicted: neutral\n",
      "Original: joy\n",
      "===\n",
      "Text: Really ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: For my last birthday you gave me a hug !\n",
      "Predicted: disgust\n",
      "Original: disgust\n",
      "===\n",
      "Text: It is a known fact that women love babies , all right ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: But I will still always come back , like this .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: What ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: No ... no ... no , no ! Do not !\n",
      "Predicted: fear\n",
      "Original: fear\n",
      "===\n",
      "Text: Seven hundred bucks !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: You know Monica you had a minor setback in your relationship with Chandler . Big deal ! It is only Chandler . I am so sorry .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Stating the obvious , but thank you . And it is not weird is it .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Ohh , you can say . Come on , I do not want you to feel like you can not tell me things .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: What ? !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: I am fine .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: 4 : 00 a . m .\n",
      "Predicted: neutral\n",
      "Original: disgust\n",
      "===\n",
      "Text: I am sorry .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: No , you did not . The only thing that freaked me out was you saying that nothing could ever happen between us .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: They were so ornate and beautiful , I mean look at that !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: It is a tradition , like the parade . If the parade decided it was gay , moved out , and abandoned its entire family .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Hey ! Guys , this is Tabatha . I will see you tomorrow .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: No . And then I called him , and he was not there .\n",
      "Predicted: neutral\n",
      "Original: sadness\n",
      "===\n",
      "Text: I am funny ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: He might still show up .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: I can not believe he did this .\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: And then whoever does gets the phone .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: And now , he is got a two year contract opposite Susan Luchhi , the first lady of daytime television , and me , me I am stuck here teaching a bunch of people , most of whom are too ugly to even be on TV .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: I do not know . You uh , you got something for me ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: \" You wanna go over to Joey and Chandler ? \"\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Excuse me , I am sorry , I am gonna have to call you back , I have got a Schemp in my office .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Ok , but you know what ? I gotta say , I am really impressed that you were able to memorize all this so quickly !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: All right , well why do not I go out with an ex ... boyfriend and do Joey a favor ? !\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: Not you guys .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: And instead my parents got me this little plastic chicken that you hop around on .\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: Oh , look at the little cat !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Ramoray !\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: Okay , so if an eight comes up , we take it as a sign and we do it !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: No ! Sorry , I just thought you were somebody else . Hi !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Oh ! No problem ! I ...\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: No , I did , but tell me again , because it is so romantic .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Oh .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: I am telling you , something wrong ! My brother does not stay out all night .\n",
      "Predicted: fear\n",
      "Original: fear\n",
      "===\n",
      "Text: Uh ... huh .\n",
      "Predicted: sadness\n",
      "Original: disgust\n",
      "===\n",
      "Text: Good deal .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Now , I am just letting you know that this is\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Well , you will have to wait your turn .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: I will not speed .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Oh yeah , that was great . Thanks to you , the hottest cocktail waitress there is quitting to teach the third grade !\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: I am gonna go talk to uh , a friend .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Hey buddy , do you think I can borrow your uniform this Thursday ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Look , just because some idiot drew on your face does not mean you should not have any fun !\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Ross !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Come on Chloe ! Finish up with your customer first . Come on Chloe ! Come on Chloe ! !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: No . When it comes to sweets , he is surprisingly strict .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: For him .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Where you going ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Here a chick , there a chick , everywhere a chick ... chick ... chickeeeen .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Did you make your deposit ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: It happened in London .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: All right .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Umm , okay , okay , look .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: See , yes .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Do not give me that deep freeze .\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: I am .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: He wants to talk to you again .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: What a sweet story .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Oh God , Ross , I cannot do this .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: It is possible , they have really sharp edges .\n",
      "Predicted: sadness\n",
      "Original: neutral\n",
      "===\n",
      "Text: Well , if you think it will help .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: No ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Estelle said I did not get it .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: Ow ! Did you just bite me ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Yeah , yeah I got that .\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: Hello .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Uh sir , may I see your tickets please ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: I am with Hamilton !\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: What the hell is that ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: No !\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: Because I sure as hell can not figure it out !\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: Joey , where are the Jell ... o shots ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Well do you want some help ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Joey , do you have a minute ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Oh God .\n",
      "Predicted: sadness\n",
      "Original: sadness\n",
      "===\n",
      "Text: You can not ask us son , that is cheating .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: No .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Whoa !\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: What ?\n",
      "Predicted: surprise\n",
      "Original: surprise\n",
      "===\n",
      "Text: Hey lady , your day over ! It is my turn !\n",
      "Predicted: anger\n",
      "Original: anger\n",
      "===\n",
      "Text: Joey , can I talk to you for a second ?\n",
      "Predicted: neutral\n",
      "Original: fear\n",
      "===\n",
      "Text: You know , I do not think we brought enough stuff . Did you forget to pack the baby anvil ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Yep !\n",
      "Predicted: joy\n",
      "Original: joy\n",
      "===\n",
      "Text: I am sorry , do I know you ?\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Thank you , but I want to remove it Pheebs . I do not want to make it savory .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Did anybody else feel they just wanted to peel the skin off their body , to have something else to do ?\n",
      "Predicted: surprise\n",
      "Original: disgust\n",
      "===\n",
      "Text: Yeah , we saw this really interesting website about marriage and how totally unnecessary it is and how its just a way for the government to keep tabs on you .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: He had C . H . E . E . S . E .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n",
      "Text: Jill says vestibule ... I am going with vestibule .\n",
      "Predicted: neutral\n",
      "Original: neutral\n",
      "===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m video_name \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m video_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_video_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m: to_device(\n\u001b[0;32m----> 9\u001b[0m         \u001b[43mmodality_transform\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_name\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     10\u001b[0m         device,\n\u001b[1;32m     11\u001b[0m     ),\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: to_device(\n\u001b[1;32m     13\u001b[0m         tokenizer(\n\u001b[1;32m     14\u001b[0m             batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m             max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m77\u001b[39m,\n\u001b[1;32m     16\u001b[0m             padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m             truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m             return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m         ),\n\u001b[1;32m     20\u001b[0m         device,\n\u001b[1;32m     21\u001b[0m     ),\n\u001b[1;32m     22\u001b[0m }\n\u001b[1;32m     24\u001b[0m result \u001b[38;5;241m=\u001b[39m text_video_classif(inputs)\n\u001b[1;32m     25\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/code/semeval/experiments/kosenko/language_bind/LanguageBind/languagebind/video/processing_video.py:161\u001b[0m, in \u001b[0;36mLanguageBindVideoProcessor.__call__\u001b[0;34m(self, images, text, context_length, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     images \u001b[38;5;241m=\u001b[39m make_list_of_images(images)\n\u001b[0;32m--> 161\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_processor(\n\u001b[1;32m    163\u001b[0m             image,\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform,\n\u001b[1;32m    165\u001b[0m             video_decode_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvision_config\u001b[38;5;241m.\u001b[39mvideo_decode_backend,\n\u001b[1;32m    166\u001b[0m             num_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvision_config\u001b[38;5;241m.\u001b[39mnum_frames,\n\u001b[1;32m    167\u001b[0m         )\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    169\u001b[0m     ]\n\u001b[1;32m    170\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(image_features)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/code/semeval/experiments/kosenko/language_bind/LanguageBind/languagebind/video/processing_video.py:162\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     images \u001b[38;5;241m=\u001b[39m make_list_of_images(images)\n\u001b[1;32m    161\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 162\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_processor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvideo_decode_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_decode_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    169\u001b[0m     ]\n\u001b[1;32m    170\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(image_features)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/code/semeval/experiments/kosenko/language_bind/LanguageBind/languagebind/video/processing_video.py:105\u001b[0m, in \u001b[0;36mload_and_transform_video\u001b[0;34m(video_path, transform, video_decode_backend, clip_start_sec, clip_end_sec, num_frames)\u001b[0m\n\u001b[1;32m    103\u001b[0m duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(decord_vr)\n\u001b[1;32m    104\u001b[0m frame_id_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, duration \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, num_frames, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m video_data \u001b[38;5;241m=\u001b[39m \u001b[43mdecord_vr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_id_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m video_data \u001b[38;5;241m=\u001b[39m video_data\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (T, H, W, C) -> (C, T, H, W)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m video_outputs \u001b[38;5;241m=\u001b[39m transform(video_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/decord/video_reader.py:175\u001b[0m, in \u001b[0;36mVideoReader.get_batch\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    174\u001b[0m indices \u001b[38;5;241m=\u001b[39m _nd\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_indices(indices))\n\u001b[0;32m--> 175\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_CAPI_VideoReaderGetBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bridge_out(arr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/decord/_ffi/_ctypes/function.py:173\u001b[0m, in \u001b[0;36mFunctionBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    171\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m DECORDValue()\n\u001b[1;32m    172\u001b[0m ret_tcode \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int()\n\u001b[0;32m--> 173\u001b[0m check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDECORDFuncCall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_tcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    176\u001b[0m _ \u001b[38;5;241m=\u001b[39m temp_args\n\u001b[1;32m    177\u001b[0m _ \u001b[38;5;241m=\u001b[39m args\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_data:\n",
    "        # print(batch)\n",
    "        base_video_path = \"/code/SemEval-2024_Task3/training_data/train\"\n",
    "        video_name = batch[\"video_name\"]\n",
    "        video_name = f\"{base_video_path}/{video_name}\"\n",
    "        inputs = {\n",
    "            \"video\": to_device(\n",
    "                modality_transform[\"video\"](video_name),\n",
    "                device,\n",
    "            ),\n",
    "            \"language\": to_device(\n",
    "                tokenizer(\n",
    "                    batch[\"text\"],\n",
    "                    max_length=77,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                ),\n",
    "                device,\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        result = text_video_classif(inputs)\n",
    "        result = result.argmax(-1).item()\n",
    "        result = labels2emotions[result]\n",
    "        print(f\"Text: {batch['text']}\")\n",
    "        print(f'Predicted: {result}\\nOriginal: {batch[\"emotion\"]}')\n",
    "        print(\"===\")\n",
    "        # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
